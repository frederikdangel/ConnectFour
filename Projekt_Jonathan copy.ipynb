{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0415bf6fd9d1100dfd2066d2c88b34aec972079c3c4f1b183feab8a8bfd8d55a2",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "from kaggle_environments import make, evaluate\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dim_in, hidden_dim, dim_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_in, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, dim_out)\n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        x = F.relu(self.fc1(input))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.relu(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience',\n",
    "           field_names=['state', 'action', 'reward', 'next_state', 'done'])\n",
    "class ExperienceReplay:\n",
    "  def __init__(self, capacity):\n",
    "      self.buffer = []\n",
    "      self.capacity = capacity\n",
    "  def __len__(self):\n",
    "      return len(self.buffer)\n",
    "  def append(self, experience):\n",
    "      if len(self.buffer) >= self.capacity:\n",
    "          self.buffer.pop()\n",
    "      self.buffer.append(experience)\n",
    "\n",
    "  def sample(self, batch_size, device):\n",
    "      indices = np.random.choice(len(self.buffer), batch_size,\n",
    "                replace=False)\n",
    "      zipped = list(zip(*[self.buffer[i] for i in indices]))\n",
    "      return torch.tensor(zipped[0], dtype = torch.float).to(device), torch.tensor(zipped[1], dtype = torch.long).to(device), torch.tensor(zipped[2], dtype = torch.float).to(device), torch.tensor(zipped[3], dtype = torch.float).to(device), torch.tensor(zipped[4], dtype = torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeAction(actionList, device,epsilon):\n",
    "        if np.random.random() < epsilon:\n",
    "            return torch.tensor(np.random.choice(len(actionList))).to(device)\n",
    "        else:\n",
    "            return torch.argmax(actionList).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeReward(reward):\n",
    "    if reward == None:\n",
    "        return -10\n",
    "    if reward == 0:\n",
    "        return 1/42\n",
    "    else:\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def generateEpisodes(amount, model,replayBuffer, env,device,epsilon):\n",
    "    batchReward = 0\n",
    "    firstQValues = []\n",
    "    start = True\n",
    "    steps = 0\n",
    "    with torch.no_grad(): \n",
    "        for _ in range(amount):\n",
    "            done = False\n",
    "            env.reset()\n",
    "            trainer = env.train([None, \"random\"])\n",
    "            obs = trainer.reset()\n",
    "            while not done:\n",
    "                tensor = torch.tensor(obs.board, dtype = torch.float).to(device)\n",
    "                qValues = model(tensor)\n",
    "                action = takeAction(qValues, device,epsilon)\n",
    "                if start:\n",
    "                    start = False\n",
    "                    firstQValues.append(qValues)\n",
    "                old_obs = obs\n",
    "                obs, reward, done, info = trainer.step(action.item())\n",
    "                reward = changeReward(reward)\n",
    "                exp = Experience(old_obs.board, action, reward, obs.board, float(done))\n",
    "                replayBuffer.append(exp)\n",
    "                batchReward+=reward\n",
    "                steps+=1\n",
    "    return batchReward/amount, firstQValues, steps/amount"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, qModel, replayBuffer, optimizer, loss_function, device,batchSize, alpha, gamma):\n",
    "    states, actions, rewards, next_states, dones = replayBuffer.sample(batchSize, device)\n",
    "    optimizer.zero_grad()\n",
    "    value = torch.index_select(model(states), 1 , actions)[1]\n",
    "    qValue = torch.max(qModel(next_states),1)[0]\n",
    "    target = rewards + (gamma * qValue)*(1-dones)\n",
    "    loss = loss_function(value, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    return loss    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_percentages(agent1, agent2, n_rounds=100):\n",
    "    # Use default Connect Four setup\n",
    "    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n",
    "    # Agent 1 goes first (roughly) half the time          \n",
    "    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n",
    "    # Agent 2 goes first (roughly) half the time      \n",
    "    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n",
    "    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n",
    "    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n",
    "    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n",
    "    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def agent1(obs, config):\n",
    "    model = Net(config.columns*config.rows, 300, config.columns)\n",
    "    model.load_state_dict(torch.load(\"model_state\"))\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor(obs['board'], dtype=torch.float)\n",
    "        print(state)\n",
    "        col = model(state).argmax().item()\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(hiddenDim, episodes, batchSize, device):\n",
    "    env = make(\"connectx\")\n",
    "    env.render()\n",
    "    model = Net(env.configuration.columns*env.configuration.rows, hiddenDim, env.configuration.columns).to(device)\n",
    "    qModel = Net(env.configuration.columns*env.configuration.rows, hiddenDim, env.configuration.columns).to(device)\n",
    "    qModel.load_state_dict(model.state_dict())\n",
    "    qModel.eval()\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(params = model.parameters(), lr=0.1)\n",
    "    buffer = ExperienceReplay(10000)\n",
    "    idx = 0\n",
    "    while True:\n",
    "        epsilon =  (0.9-0.1)*max((100-idx)/100,0) + 0.1\n",
    "        batchReward, firstQValues, steps = generateEpisodes(episodes, model, buffer, env,device, epsilon)\n",
    "        loss = train(model, qModel, buffer, optimizer,loss_function,device,batchSize, 0.01, 0.99)  \n",
    "        if idx % 20 == 0:\n",
    "            qModel.load_state_dict(model.state_dict())\n",
    "            print(\"idx: \" + str(idx) + \" meanReward generateEpisodes: \" +  str(batchReward) + \" meanLoss: \" + str(loss/batchSize))\n",
    "            print(\"first qs\" + str(firstQValues))\n",
    "            print(\"steps: \" + str(steps) )\n",
    "            torch.save(model.state_dict(), \"model_state\")\n",
    "            get_win_percentages(agent1, \"random\")\n",
    "        idx+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "idx: 0 meanReward generateEpisodes: -2.347619047619075 meanLoss: tensor(0.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "first qs[tensor([0.0148, 0.0000, 0.0086, 0.0000, 0.0000, 0.0344, 0.0026],\n",
      "       device='cuda:0')]\n",
      "steps: 10.34\n",
      "Agent 1 Win Percentage: 0.7\n",
      "Agent 2 Win Percentage: 0.02\n",
      "Number of Invalid Plays by Agent 1: 28\n",
      "Number of Invalid Plays by Agent 2: 0\n",
      "idx: 20 meanReward generateEpisodes: -2.104285714285744 meanLoss: tensor(25.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "first qs[tensor([1.3702, 0.0000, 0.0000, 4.3049, 0.0000, 0.0000, 0.0000],\n",
      "       device='cuda:0')]\n",
      "steps: 10.06\n",
      "Agent 1 Win Percentage: 0.76\n",
      "Agent 2 Win Percentage: 0.04\n",
      "Number of Invalid Plays by Agent 1: 20\n",
      "Number of Invalid Plays by Agent 2: 0\n",
      "idx: 40 meanReward generateEpisodes: -2.907142857142891 meanLoss: tensor(9.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "first qs[tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')]\n",
      "steps: 8.68\n",
      "Agent 1 Win Percentage: 0.74\n",
      "Agent 2 Win Percentage: 0.06\n",
      "Number of Invalid Plays by Agent 1: 20\n",
      "Number of Invalid Plays by Agent 2: 0\n",
      "idx: 60 meanReward generateEpisodes: -2.175952380952404 meanLoss: tensor(0.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "first qs[tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')]\n",
      "steps: 7.05\n",
      "Agent 1 Win Percentage: 0.72\n",
      "Agent 2 Win Percentage: 0.03\n",
      "Number of Invalid Plays by Agent 1: 25\n",
      "Number of Invalid Plays by Agent 2: 0\n",
      "idx: 80 meanReward generateEpisodes: -2.272142857142872 meanLoss: tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "first qs[tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')]\n",
      "steps: 5.95\n",
      "Agent 1 Win Percentage: 0.69\n",
      "Agent 2 Win Percentage: 0.06\n",
      "Number of Invalid Plays by Agent 1: 25\n",
      "Number of Invalid Plays by Agent 2: 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-afeaf618df34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-51156c5c86ee>\u001b[0m in \u001b[0;36mtrain2\u001b[1;34m(hiddenDim, episodes, batchSize, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mbatchReward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirstQValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerateEpisodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-2ae73c69deec>\u001b[0m in \u001b[0;36mgenerateEpisodes\u001b[1;34m(amount, model, replayBuffer, env, device, epsilon)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mqValues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtakeAction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train2(300, 100, 32, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "model = Net(env.configuration.columns*env.configuration.rows, 300, env.configuration.columns)\n",
    "model.load_state_dict(torch.load(\"model_state\"))\n",
    "def agent(observation, configuration):\n",
    "    with torch.no_grad():\n",
    "        result = model(torch.tensor(observation.board, dtype = torch.float))\n",
    "        print(result)\n",
    "        result = int(torch.argmax(result))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([36.6298, 43.0849, 33.7678, 36.0474, 42.9718, 43.7050, 40.6634])\ntensor([37.8858, 44.3841, 33.5597, 35.1042, 44.7194, 45.5465, 41.7299])\ntensor([39.0033, 46.4624, 33.7962, 33.1300, 44.6875, 47.8918, 44.8106])\ntensor([38.9665, 46.3897, 33.7872, 33.2183, 44.7269, 47.7831, 44.6775])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<iframe srcdoc=\"<!--\n  Copyright 2020 Kaggle Inc\n\n  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n      http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n-->\n<!DOCTYPE html>\n<html lang=&quot;en&quot;>\n  <head>\n    <title>Kaggle Simulation Player</title>\n    <meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1&quot; />\n    <link\n      rel=&quot;stylesheet&quot;\n      href=&quot;https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.css&quot;\n      crossorigin=&quot;anonymous&quot;\n    />\n    <style type=&quot;text/css&quot;>\n      html,\n      body {\n        height: 100%;\n        font-family: sans-serif;\n        margin: 0px;\n      }\n      canvas {\n        /* image-rendering: -moz-crisp-edges;\n        image-rendering: -webkit-crisp-edges;\n        image-rendering: pixelated;\n        image-rendering: crisp-edges; */\n      }\n    </style>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/dist/preact.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/preact@10.0.1/hooks/dist/hooks.umd.js&quot;></script>\n    <script src=&quot;https://unpkg.com/htm@2.2.1/dist/htm.umd.js&quot;></script>\n    <script>\n      // Polyfill for Styled Components\n      window.React = {\n        ...preact,\n        createElement: preact.h,\n        PropTypes: { func: {} },\n      };\n    </script>\n    <script src=&quot;https://unpkg.com/styled-components@3.5.0-0/dist/styled-components.min.js&quot;></script>\n  </head>\n  <body>\n    <script>\n      \nwindow.kaggle = {\n  &quot;debug&quot;: true,\n  &quot;playing&quot;: true,\n  &quot;step&quot;: 0,\n  &quot;controls&quot;: true,\n  &quot;environment&quot;: {\n    &quot;id&quot;: &quot;843f3d98-c45a-11eb-a20a-b05cdadc0882&quot;,\n    &quot;name&quot;: &quot;connectx&quot;,\n    &quot;title&quot;: &quot;ConnectX&quot;,\n    &quot;description&quot;: &quot;Classic Connect in a row but configurable.&quot;,\n    &quot;version&quot;: &quot;1.0.1&quot;,\n    &quot;configuration&quot;: {\n      &quot;episodeSteps&quot;: 1000,\n      &quot;actTimeout&quot;: 2,\n      &quot;runTimeout&quot;: 1200,\n      &quot;columns&quot;: 7,\n      &quot;rows&quot;: 6,\n      &quot;inarow&quot;: 4,\n      &quot;agentTimeout&quot;: 60,\n      &quot;timeout&quot;: 2\n    },\n    &quot;specification&quot;: {\n      &quot;action&quot;: {\n        &quot;description&quot;: &quot;Column to drop a checker onto the board.&quot;,\n        &quot;type&quot;: &quot;integer&quot;,\n        &quot;minimum&quot;: 0,\n        &quot;default&quot;: 0\n      },\n      &quot;agents&quot;: [\n        2\n      ],\n      &quot;configuration&quot;: {\n        &quot;episodeSteps&quot;: {\n          &quot;description&quot;: &quot;Maximum number of steps in the episode.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;minimum&quot;: 1,\n          &quot;default&quot;: 1000\n        },\n        &quot;actTimeout&quot;: {\n          &quot;description&quot;: &quot;Maximum runtime (seconds) to obtain an action from an agent.&quot;,\n          &quot;type&quot;: &quot;number&quot;,\n          &quot;minimum&quot;: 0,\n          &quot;default&quot;: 2\n        },\n        &quot;runTimeout&quot;: {\n          &quot;description&quot;: &quot;Maximum runtime (seconds) of an episode (not necessarily DONE).&quot;,\n          &quot;type&quot;: &quot;number&quot;,\n          &quot;minimum&quot;: 0,\n          &quot;default&quot;: 1200\n        },\n        &quot;columns&quot;: {\n          &quot;description&quot;: &quot;The number of columns on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 7,\n          &quot;minimum&quot;: 1\n        },\n        &quot;rows&quot;: {\n          &quot;description&quot;: &quot;The number of rows on the board&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 6,\n          &quot;minimum&quot;: 1\n        },\n        &quot;inarow&quot;: {\n          &quot;description&quot;: &quot;The number of checkers in a row required to win.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 4,\n          &quot;minimum&quot;: 1\n        },\n        &quot;agentTimeout&quot;: {\n          &quot;description&quot;: &quot;Obsolete field kept for backwards compatibility, please use observation.remainingOverageTime.&quot;,\n          &quot;type&quot;: &quot;number&quot;,\n          &quot;minimum&quot;: 0,\n          &quot;default&quot;: 60\n        },\n        &quot;timeout&quot;: {\n          &quot;description&quot;: &quot;Obsolete copy of actTimeout maintained for backwards compatibility. May be removed in the future.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;default&quot;: 2,\n          &quot;minimum&quot;: 0\n        }\n      },\n      &quot;info&quot;: {},\n      &quot;observation&quot;: {\n        &quot;remainingOverageTime&quot;: {\n          &quot;description&quot;: &quot;Total remaining banked time (seconds) that can be used in excess of per-step actTimeouts -- agent is disqualified with TIMEOUT status when this drops below 0.&quot;,\n          &quot;shared&quot;: false,\n          &quot;type&quot;: &quot;number&quot;,\n          &quot;minimum&quot;: 0,\n          &quot;default&quot;: 60\n        },\n        &quot;step&quot;: {\n          &quot;description&quot;: &quot;Current step within the episode.&quot;,\n          &quot;type&quot;: &quot;integer&quot;,\n          &quot;shared&quot;: true,\n          &quot;minimum&quot;: 0,\n          &quot;default&quot;: 0\n        },\n        &quot;board&quot;: {\n          &quot;description&quot;: &quot;Serialized grid (rows x columns). 0 = Empty, 1 = P1, 2 = P2&quot;,\n          &quot;type&quot;: &quot;array&quot;,\n          &quot;shared&quot;: true,\n          &quot;default&quot;: []\n        },\n        &quot;mark&quot;: {\n          &quot;defaults&quot;: [\n            1,\n            2\n          ],\n          &quot;description&quot;: &quot;Which checkers are the agents.&quot;,\n          &quot;enum&quot;: [\n            1,\n            2\n          ]\n        }\n      },\n      &quot;reward&quot;: {\n        &quot;description&quot;: &quot;-1 = Lost, 0 = Draw/Ongoing, 1 = Won&quot;,\n        &quot;enum&quot;: [\n          -1,\n          0,\n          1\n        ],\n        &quot;default&quot;: 0,\n        &quot;type&quot;: [\n          &quot;number&quot;,\n          &quot;null&quot;\n        ]\n      }\n    },\n    &quot;steps&quot;: [\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 0,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 1,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 2,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 3,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 3,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              0\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 4,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 6,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 5,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              2,\n              0,\n              1,\n              2\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 6,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;ACTIVE&quot;\n        },\n        {\n          &quot;action&quot;: 4,\n          &quot;reward&quot;: 0,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;INACTIVE&quot;\n        }\n      ],\n      [\n        {\n          &quot;action&quot;: 5,\n          &quot;reward&quot;: 1,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;step&quot;: 7,\n            &quot;board&quot;: [\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              0,\n              0,\n              1,\n              0,\n              0,\n              0,\n              0,\n              2,\n              2,\n              1,\n              2\n            ],\n            &quot;mark&quot;: 1\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        },\n        {\n          &quot;action&quot;: 0,\n          &quot;reward&quot;: -1,\n          &quot;info&quot;: {},\n          &quot;observation&quot;: {\n            &quot;remainingOverageTime&quot;: 60,\n            &quot;mark&quot;: 2\n          },\n          &quot;status&quot;: &quot;DONE&quot;\n        }\n      ]\n    ],\n    &quot;rewards&quot;: [\n      1,\n      -1\n    ],\n    &quot;statuses&quot;: [\n      &quot;DONE&quot;,\n      &quot;DONE&quot;\n    ],\n    &quot;schema_version&quot;: 1,\n    &quot;info&quot;: {}\n  },\n  &quot;logs&quot;: [\n    [],\n    [],\n    [],\n    [\n      {\n        &quot;duration&quot;: 0.005786,\n        &quot;stdout&quot;: &quot;tensor([36.6298, 43.0849, 33.7678, 36.0474, 42.9718, 43.7050, 40.6634])\\n&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      },\n      {}\n    ],\n    [\n      {},\n      {\n        &quot;duration&quot;: 2.1e-05,\n        &quot;stdout&quot;: &quot;&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      }\n    ],\n    [\n      {\n        &quot;duration&quot;: 0.000846,\n        &quot;stdout&quot;: &quot;tensor([37.8858, 44.3841, 33.5597, 35.1042, 44.7194, 45.5465, 41.7299])\\n&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      },\n      {}\n    ],\n    [\n      {},\n      {\n        &quot;duration&quot;: 1.3e-05,\n        &quot;stdout&quot;: &quot;&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      }\n    ],\n    [\n      {\n        &quot;duration&quot;: 0.000805,\n        &quot;stdout&quot;: &quot;tensor([39.0033, 46.4624, 33.7962, 33.1300, 44.6875, 47.8918, 44.8106])\\n&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      },\n      {}\n    ],\n    [\n      {},\n      {\n        &quot;duration&quot;: 8e-06,\n        &quot;stdout&quot;: &quot;&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      }\n    ],\n    [\n      {\n        &quot;duration&quot;: 0.000615,\n        &quot;stdout&quot;: &quot;tensor([38.9665, 46.3897, 33.7872, 33.2183, 44.7269, 47.7831, 44.6775])\\n&quot;,\n        &quot;stderr&quot;: &quot;&quot;\n      },\n      {}\n    ]\n  ],\n  &quot;mode&quot;: &quot;ipython&quot;,\n  &quot;width&quot;: 500,\n  &quot;height&quot;: 450\n};\n\n\nwindow.kaggle.renderer = // Copyright 2020 Kaggle Inc\n//\n// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\nfunction renderer({\n  act,\n  agents,\n  environment,\n  frame,\n  height = 400,\n  interactive,\n  isInteractive,\n  parent,\n  step,\n  update,\n  width = 400,\n}) {\n  // Configuration.\n  const { rows, columns, inarow } = environment.configuration;\n\n  // Common Dimensions.\n  const unit = 8;\n  const minCanvasSize = Math.min(height, width);\n  const minOffset = minCanvasSize > 400 ? 30 : unit / 2;\n  const cellSize = Math.min(\n    (width - minOffset * 2) / columns,\n    (height - minOffset * 2) / rows\n  );\n  const cellInset = 0.8;\n  const pieceScale = cellSize / 100;\n  const xOffset = Math.max(0, (width - cellSize * columns) / 2);\n  const yOffset = Math.max(0, (height - cellSize * rows) / 2);\n\n  // Canvas Setup.\n  let canvas = parent.querySelector(&quot;canvas&quot;);\n  if (!canvas) {\n    canvas = document.createElement(&quot;canvas&quot;);\n    parent.appendChild(canvas);\n\n    if (interactive) {\n      canvas.addEventListener(&quot;click&quot;, evt => {\n        if (!isInteractive()) return;\n        const rect = evt.target.getBoundingClientRect();\n        const col = Math.floor((evt.clientX - rect.left - xOffset) / cellSize);\n        if (col >= 0 && col < columns) act(col);\n      });\n    }\n  }\n  canvas.style.cursor = isInteractive() ? &quot;pointer&quot; : &quot;default&quot;;\n\n  // Character Paths (based on 100x100 tiles).\n  const kPath = new Path2D(\n    `M78.3,96.5c-0.1,0.4-0.5,0.6-1.1,0.6H64.9c-0.7,0-1.4-0.3-1.9-1l-20.3-26L37,75.5v20.1 c0,0.9-0.5,1.4-1.4,1.4H26c-0.9,0-1.4-0.5-1.4-1.4V3.9c0-0.9,0.5-1.4,1.4-1.4h9.5C36.5,2.5,37,3,37,3.9v56.5l24.3-24.7 c0.6-0.6,1.3-1,1.9-1H76c0.6,0,0.9,0.2,1.1,0.7c0.2,0.6,0.1,1-0.1,1.2l-25.7,25L78,95.1C78.4,95.5,78.5,95.9,78.3,96.5z`\n  );\n  const goose1Path = new Path2D(\n    `M8.8,92.7c-4-18.5,4.7-37.2,20.7-46.2c0,0,2.7-1.4,3.4-1.9c2.2-1.6,3-2.1,3-5c0-5-2.1-7.2-2.1-7.2 c-3.9-3.3-6.3-8.2-6.3-13.7c0-10,8.1-18.1,18.1-18.1s18.1,8.1,18.1,18.1c0,6-1.5,32.7-2.3,38.8l-0.1,1`\n  );\n  const goose2Path = new Path2D(\n    `M27.4,19L8.2,27.6c0,0-7.3,2.9,2.6,5c6.1,1.3,24,5.9,24,5.9l1,0.3`\n  );\n  const goose3Path = new Path2D(\n    `M63.7,99.6C52.3,99.6,43,90.3,43,78.9s9.3-20.7,20.7-20.7c10.6,0,34.4,0.1,35.8,9`\n  );\n\n  // Canvas setup and reset.\n  let c = canvas.getContext(&quot;2d&quot;);\n  canvas.width = width;\n  canvas.height = height;\n  c.fillStyle = &quot;#000B2A&quot;;\n  c.fillRect(0, 0, canvas.width, canvas.height);\n\n  const getRowCol = cell => [Math.floor(cell / columns), cell % columns];\n\n  const getColor = (mark, opacity = 1) => {\n    if (mark === 1) return `rgba(0,255,255,${opacity})`;\n    if (mark === 2) return `rgba(255,255,255,${opacity})`;\n    return &quot;#fff&quot;;\n  };\n\n  const drawCellCircle = (cell, xFrame = 1, yFrame = 1, radiusOffset = 0) => {\n    const [row, col] = getRowCol(cell);\n    c.arc(\n      xOffset + xFrame * (col * cellSize + cellSize / 2),\n      yOffset + yFrame * (row * cellSize + cellSize / 2),\n      (cellInset * cellSize) / 2 - radiusOffset,\n      2 * Math.PI,\n      false\n    );\n  };\n\n  // Render the pieces.\n  const board = environment.steps[step][0].observation.board;\n\n  const drawPiece = mark => {\n    // Base Styles.\n    const opacity = minCanvasSize < 300 ? 0.6 - minCanvasSize / 1000 : 0.1;\n    c.fillStyle = getColor(mark, opacity);\n    c.strokeStyle = getColor(mark);\n    c.shadowColor = getColor(mark);\n    c.shadowBlur = 8 / cellInset;\n    c.lineWidth = 1 / cellInset;\n\n    // Outer circle.\n    c.save();\n    c.beginPath();\n    c.arc(50, 50, 50, 2 * Math.PI, false);\n    c.closePath();\n    c.lineWidth *= 4;\n    c.stroke();\n    c.fill();\n    c.restore();\n\n    // Inner circle.\n    c.beginPath();\n    c.arc(50, 50, 40, 2 * Math.PI, false);\n    c.closePath();\n    c.stroke();\n\n    // Kaggle &quot;K&quot;.\n    if (mark === 1) {\n      const scale = 0.54;\n      c.save();\n      c.translate(23, 23);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(kPath);\n      c.restore();\n    }\n\n    // Kaggle &quot;Goose&quot;.\n    if (mark === 2) {\n      const scale = 0.6;\n      c.save();\n      c.translate(24, 28);\n      c.scale(scale, scale);\n      c.lineWidth /= scale;\n      c.shadowBlur /= scale;\n      c.stroke(goose1Path);\n      c.stroke(goose2Path);\n      c.stroke(goose3Path);\n      c.beginPath();\n      c.arc(38.5, 18.6, 2.7, 0, Math.PI * 2, false);\n      c.closePath();\n      c.fill();\n      c.restore();\n    }\n  };\n\n  for (let i = 0; i < board.length; i++) {\n    const [row, col] = getRowCol(i);\n    if (board[i] === 0) continue;\n    // Easing In.\n    let yFrame = Math.min(\n      (columns * Math.pow(frame, 3)) / Math.floor(i / columns),\n      1\n    );\n\n    if (\n      step > 1 &&\n      environment.steps[step - 1][0].observation.board[i] === board[i]\n    ) {\n      yFrame = 1;\n    }\n\n    c.save();\n    c.translate(\n      xOffset + cellSize * col + (cellSize - cellSize * cellInset) / 2,\n      yOffset +\n        yFrame * (cellSize * row) +\n        (cellSize - cellSize * cellInset) / 2\n    );\n    c.scale(pieceScale * cellInset, pieceScale * cellInset);\n    drawPiece(board[i]);\n    c.restore();\n  }\n\n  // Background Gradient.\n  const bgRadius = (Math.min(rows, columns) * cellSize) / 2;\n  const bgStyle = c.createRadialGradient(\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    0,\n    xOffset + (cellSize * columns) / 2,\n    yOffset + (cellSize * rows) / 2,\n    bgRadius\n  );\n  bgStyle.addColorStop(0, &quot;#000B49&quot;);\n  bgStyle.addColorStop(1, &quot;#000B2A&quot;);\n\n  // Render the board overlay.\n  c.beginPath();\n  c.rect(0, 0, canvas.width, canvas.height);\n  c.closePath();\n  c.shadowBlur = 0;\n  for (let i = 0; i < board.length; i++) {\n    drawCellCircle(i);\n    c.closePath();\n  }\n  c.fillStyle = bgStyle;\n  c.fill(&quot;evenodd&quot;);\n\n  // Render the board overlay cell outlines.\n  for (let i = 0; i < board.length; i++) {\n    c.beginPath();\n    drawCellCircle(i);\n    c.strokeStyle = &quot;#0361B2&quot;;\n    c.lineWidth = 1;\n    c.stroke();\n    c.closePath();\n  }\n\n  const drawLine = (fromCell, toCell) => {\n    if (frame < 0.5) return;\n    const lineFrame = (frame - 0.5) / 0.5;\n    const x1 = xOffset + (fromCell % columns) * cellSize + cellSize / 2;\n    const x2 =\n      x1 +\n      lineFrame *\n        (xOffset + ((toCell % columns) * cellSize + cellSize / 2) - x1);\n    const y1 =\n      yOffset + Math.floor(fromCell / columns) * cellSize + cellSize / 2;\n    const y2 =\n      y1 +\n      lineFrame *\n        (yOffset + Math.floor(toCell / columns) * cellSize + cellSize / 2 - y1);\n    c.beginPath();\n    c.lineCap = &quot;round&quot;;\n    c.lineWidth = 4;\n    c.strokeStyle = getColor(board[fromCell]);\n    c.shadowBlur = 8;\n    c.shadowColor = getColor(board[fromCell]);\n    c.moveTo(x1, y1);\n    c.lineTo(x2, y2);\n    c.stroke();\n  };\n\n  // Generate a graph of the board.\n  const getCell = (cell, rowOffset, columnOffset) => {\n    const row = Math.floor(cell / columns) + rowOffset;\n    const col = (cell % columns) + columnOffset;\n    if (row < 0 || row >= rows || col < 0 || col >= columns) return -1;\n    return col + row * columns;\n  };\n  const makeNode = cell => {\n    const node = { cell, directions: [], value: board[cell] };\n    for (let r = -1; r <= 1; r++) {\n      for (let c = -1; c <= 1; c++) {\n        if (r === 0 && c === 0) continue;\n        node.directions.push(getCell(cell, r, c));\n      }\n    }\n    return node;\n  };\n  const graph = board.map((_, i) => makeNode(i));\n\n  // Check for any wins!\n  const getSequence = (node, direction) => {\n    const sequence = [node.cell];\n    while (sequence.length < inarow) {\n      const next = graph[node.directions[direction]];\n      if (!next || node.value !== next.value || next.value === 0) return;\n      node = next;\n      sequence.push(node.cell);\n    }\n    return sequence;\n  };\n\n  // Check all nodes.\n  for (let i = 0; i < board.length; i++) {\n    // Check all directions (not the most efficient).\n    for (let d = 0; d < 8; d++) {\n      const seq = getSequence(graph[i], d);\n      if (seq) {\n        drawLine(seq[0], seq[inarow - 1]);\n        i = board.length;\n        break;\n      }\n    }\n  }\n\n  // Upgrade the legend.\n  if (agents.length && (!agents[0].color || !agents[0].image)) {\n    const getPieceImage = mark => {\n      const pieceCanvas = document.createElement(&quot;canvas&quot;);\n      parent.appendChild(pieceCanvas);\n      pieceCanvas.style.marginLeft = &quot;10000px&quot;;\n      pieceCanvas.width = 100;\n      pieceCanvas.height = 100;\n      c = pieceCanvas.getContext(&quot;2d&quot;);\n      c.translate(10, 10);\n      c.scale(0.8, 0.8);\n      drawPiece(mark);\n      const dataUrl = pieceCanvas.toDataURL();\n      parent.removeChild(pieceCanvas);\n      return dataUrl;\n    };\n\n    agents.forEach(agent => {\n      agent.color = getColor(agent.index + 1);\n      agent.image = getPieceImage(agent.index + 1);\n    });\n    update({ agents });\n  }\n};\n\n\n    \n    </script>\n    <script>\n      const h = htm.bind(preact.h);\n      const { useContext, useEffect, useRef, useState } = preactHooks;\n      const styled = window.styled.default;\n\n      const Context = preact.createContext({});\n\n      const Loading = styled.div`\n        animation: rotate360 1.1s infinite linear;\n        border: 8px solid rgba(255, 255, 255, 0.2);\n        border-left-color: #0cb1ed;\n        border-radius: 50%;\n        height: 40px;\n        position: relative;\n        transform: translateZ(0);\n        width: 40px;\n\n        @keyframes rotate360 {\n          0% {\n            transform: rotate(0deg);\n          }\n          100% {\n            transform: rotate(360deg);\n          }\n        }\n      `;\n\n      const Logo = styled(\n        (props) => h`\n        <a href=&quot;https://kaggle.com&quot; target=&quot;_blank&quot; className=${props.className}>\n          <svg width=&quot;62px&quot; height=&quot;20px&quot; viewBox=&quot;0 0 62 24&quot; version=&quot;1.1&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot;>\n            <g fill=&quot;#1EBEFF&quot; fill-rule=&quot;nonzero&quot;>\n              <path d=&quot;M10.2,17.8c0,0.1-0.1,0.1-0.2,0.1H7.7c-0.1,0-0.3-0.1-0.4-0.2l-3.8-4.9l-1.1,1v3.8 c0,0.2-0.1,0.3-0.3,0.3H0.3c-0.2,0-0.3-0.1-0.3-0.3V0.3C0.1,0.1,0.2,0,0.3,0h1.8c0.2,0,0.3,0.1,0.3,0.3V11L7,6.3 c0.1-0.1,0.2-0.2,0.4-0.2h2.4c0.1,0,0.2,0,0.2,0.1c0,0.1,0,0.2,0,0.2l-4.9,4.7l5.1,6.3C10.2,17.6,10.2,17.7,10.2,17.8z&quot;/>\n              <path d=&quot;M19.6,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3v-0.4c-0.8,0.6-1.8,0.9-3,0.9c-1.1,0-2-0.3-2.8-1 c-0.8-0.7-1.2-1.6-1.2-2.7c0-1.7,1.1-2.9,3.2-3.5c0.8-0.2,2.1-0.5,3.8-0.6c0.1-0.6-0.1-1.2-0.5-1.7c-0.4-0.5-1-0.7-1.7-0.7 c-1,0-2,0.4-3,1C12.2,9.1,12.1,9.1,12,9l-0.9-1.3C11,7.5,11,7.4,11.1,7.3c1.3-0.9,2.7-1.4,4.2-1.4c1.1,0,2.1,0.3,2.8,0.8 c1.1,0.8,1.7,2,1.7,3.7v7.3C19.9,17.8,19.8,17.9,19.6,17.9z M17.5,12.4c-1.7,0.2-2.9,0.4-3.5,0.7c-0.9,0.4-1.2,0.9-1.1,1.6 c0.1,0.4,0.2,0.7,0.6,0.9c0.3,0.2,0.7,0.4,1.1,0.4c1.2,0.1,2.2-0.2,2.9-1V12.4z&quot;/>\n              <path d=&quot;M30.6,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3v11.7C32,20,31.5,21.5,30.6,22.5z M29.7,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7V9.9z&quot;/>\n              <path d=&quot;M42.9,22.5c-0.9,1-2.3,1.5-4,1.5c-1,0-2-0.3-2.9-0.8c-0.2-0.1-0.4-0.3-0.7-0.5 c-0.3-0.2-0.6-0.5-0.9-0.7c-0.1-0.1-0.1-0.2,0-0.4l1.2-1.2c0.1-0.1,0.1-0.1,0.2-0.1c0.1,0,0.1,0,0.2,0.1c1,1,1.9,1.5,2.8,1.5 c2.1,0,3.2-1.1,3.2-3.3v-1.4c-0.8,0.7-1.9,1-3.3,1c-1.7,0-3-0.6-4-1.9c-0.8-1.1-1.3-2.5-1.3-4.2c0-1.6,0.4-3,1.2-4.1 c0.9-1.3,2.3-2,4-2c1.3,0,2.4,0.3,3.3,1V6.4c0-0.2,0.1-0.3,0.3-0.3H44c0.2,0,0.3,0.1,0.3,0.3v11.7C44.3,20,43.8,21.5,42.9,22.5z M42,9.9c-0.4-1.1-1.4-1.7-3-1.7c-2,0-3.1,1.3-3.1,3.8c0,1.4,0.3,2.4,1,3.1c0.5,0.5,1.2,0.8,2,0.8c1.6,0,2.7-0.6,3.1-1.7L42,9.9 L42,9.9z&quot;/>\n              <path d=&quot;M48.3,17.9h-1.8c-0.2,0-0.3-0.1-0.3-0.3V0.3c0-0.2,0.1-0.3,0.3-0.3h1.8c0.2,0,0.3,0.1,0.3,0.3 v17.3C48.5,17.8,48.5,17.9,48.3,17.9z&quot;/>\n              <path d=&quot;M61.4,12.6c0,0.2-0.1,0.3-0.3,0.3h-8.5c0.1,0.9,0.5,1.6,1.1,2.2c0.7,0.6,1.6,0.9,2.7,0.9 c1,0,1.8-0.3,2.6-0.8c0.2-0.1,0.3-0.1,0.4,0l1.2,1.3c0.1,0.1,0.1,0.3,0,0.4c-1.3,0.9-2.7,1.4-4.4,1.4c-1.8,0-3.3-0.6-4.4-1.8 c-1.1-1.2-1.7-2.7-1.7-4.5c0-1.7,0.6-3.2,1.7-4.4c1-1.1,2.4-1.6,4.1-1.6c1.6,0,2.9,0.6,4,1.7c1.1,1.2,1.6,2.6,1.5,4.4L61.4,12.6 z M58,8.7c-0.6-0.5-1.3-0.8-2.1-0.8c-0.8,0-1.5,0.3-2.1,0.8c-0.6,0.5-1,1.2-1.1,2H59C59,9.9,58.6,9.3,58,8.7z&quot;/>\n            </g>\n          </svg>\n        </a>\n      `\n      )`\n        display: inline-flex;\n      `;\n\n      const Header = styled((props) => {\n        const { environment } = useContext(Context);\n\n        return h`<div className=${props.className} >\n          <${Logo} />\n          <span><b>Left / Right Arrow:</b> Increase / Decrease Step</span><span><b>0-9 Row Keys:</b> Playback Speed</span><span><b>Space:</b> Pause / Play</span>\n          ${environment.title}\n        </div>`;\n      })`\n        align-items: center;\n        border-bottom: 4px solid #212121;\n        box-sizing: border-box;\n        color: #fff;\n        display: flex;\n        flex: 0 0 36px;\n        font-size: 14px;\n        justify-content: space-between;\n        padding: 0 8px;\n        width: 100%;\n      `;\n\n      const Renderer = styled((props) => {\n        const context = useContext(Context);\n        const { animate, debug, playing, renderer, speed } = context;\n        const ref = preact.createRef();\n\n        useEffect(async () => {\n          if (!ref.current) return;\n\n          const renderFrame = async (start, step, lastFrame) => {\n            if (step !== context.step) return;\n            if (lastFrame === 1) {\n              if (!animate) return;\n              start = Date.now();\n            }\n            const frame =\n              playing || animate\n                ? Math.min((Date.now() - start) / speed, 1)\n                : 1;\n            try {\n              if (debug) console.time(&quot;render&quot;);\n              await renderer({\n                ...context,\n                frame,\n                height: ref.current.clientHeight,\n                hooks: preactHooks,\n                parent: ref.current,\n                preact,\n                styled,\n                width: ref.current.clientWidth,\n              });\n            } catch (error) {\n              if (debug) console.error(error);\n              console.log({ ...context, frame, error });\n            } finally {\n              if (debug) console.timeEnd(&quot;render&quot;);\n            }\n            window.requestAnimationFrame(() => renderFrame(start, step, frame));\n          };\n\n          await renderFrame(Date.now(), context.step);\n        }, [ref.current, context.step, context.renderer]);\n\n        return h`<div className=${props.className} ref=${ref} />`;\n      })`\n        align-items: center;\n        box-sizing: border-box;\n        display: flex;\n        height: 100%;\n        left: 0;\n        justify-content: center;\n        position: absolute;\n        top: 0;\n        width: 100%;\n      `;\n\n      const Processing = styled((props) => {\n        const { processing } = useContext(Context);\n        const text = processing === true ? &quot;Processing...&quot; : processing;\n        return h`<div className=${props.className}>${text}</div>`;\n      })`\n        bottom: 0;\n        color: #fff;\n        font-size: 12px;\n        left: 0;\n        line-height: 24px;\n        position: absolute;\n        text-align: center;\n        width: 100%;\n      `;\n\n      const Viewer = styled((props) => {\n        const { processing } = useContext(Context);\n        return h`<div className=${props.className}>\n          <${Renderer} />\n          ${processing && h`<${Processing} />`}\n        </div>`;\n      })`\n        background-color: #000b2a;\n        background-image: radial-gradient(\n          circle closest-side,\n          #000b49,\n          #000b2a\n        );\n        display: flex;\n        flex: 1;\n        overflow: hidden;\n        position: relative;\n        width: 100%;\n      `;\n\n      // Partitions the elements of arr into subarrays of max length num.\n      const groupIntoSets = (arr, num) => {\n        const sets = [];\n        arr.forEach(a => {\n          if (sets.length === 0 || sets[sets.length - 1].length === num) {\n            sets.push([]);\n          }\n          sets[sets.length - 1].push(a);\n        });\n        return sets;\n      }\n\n      // Expects `width` input prop to set proper max-width for agent name span.\n      const Legend = styled((props) => {\n        const { agents, legend } = useContext(Context);\n\n        const agentPairs = groupIntoSets(agents.sort((a, b) => a.index - b.index), 2);\n\n        return h`<div className=${props.className}>\n          ${agentPairs.map(agentList =>\n            h`<ul>\n                ${agentList.map(a =>\n                  h`<li key=${a.id} title=&quot;id: ${a.id}&quot; style=&quot;color:${a.color || &quot;#FFF&quot;}&quot;>\n                      ${a.image && h`<img src=${a.image} />`}\n                      <span>${a.name}</span>\n                    </li>`\n                )}\n              </ul>`)}\n        </div>`;\n      })`\n        background-color: #000b2a;\n        font-family: sans-serif;\n        font-size: 14px;\n        height: 48px;\n        width: 100%;\n\n        ul {\n          align-items: center;\n          display: flex;\n          flex-direction: row;\n          justify-content: center;\n        }\n\n        li {\n          align-items: center;\n          display: inline-flex;\n          transition: color 1s;\n        }\n\n        span {\n          max-width: ${p => (p.width || 400) * 0.5 - 36}px;\n          overflow: hidden;\n          text-overflow: ellipsis;\n          white-space: nowrap;\n        }\n\n        img {\n          height: 24px;\n          margin-left: 4px;\n          margin-right: 4px;\n          width: 24px;\n        }\n      `;\n\n      const StepInput = styled.input.attrs({\n        type: &quot;range&quot;,\n      })`\n        appearance: none;\n        background: rgba(255, 255, 255, 0.15);\n        border-radius: 2px;\n        display: block;\n        flex: 1;\n        height: 4px;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n        width: 100%;\n\n        &:hover {\n          opacity: 1;\n        }\n\n        &::-webkit-slider-thumb {\n          appearance: none;\n          background: #1ebeff;\n          border-radius: 100%;\n          cursor: pointer;\n          height: 12px;\n          margin: 0;\n          position: relative;\n          width: 12px;\n\n          &::after {\n            content: &quot;&quot;;\n            position: absolute;\n            top: 0px;\n            left: 0px;\n            width: 200px;\n            height: 8px;\n            background: green;\n          }\n        }\n      `;\n\n      const PlayButton = styled.button`\n        align-items: center;\n        background: none;\n        border: none;\n        color: white;\n        cursor: pointer;\n        display: flex;\n        flex: 0 0 56px;\n        font-size: 20px;\n        height: 40px;\n        justify-content: center;\n        opacity: 0.8;\n        outline: none;\n        transition: opacity 0.2s;\n\n        &:hover {\n          opacity: 1;\n        }\n      `;\n\n      const StepCount = styled.span`\n        align-items: center;\n        color: white;\n        display: flex;\n        font-size: 14px;\n        justify-content: center;\n        opacity: 0.8;\n        padding: 0 16px;\n        pointer-events: none;\n      `;\n\n      const Controls = styled((props) => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n        const value = step + 1;\n        const onClick = () => (playing ? pause() : play());\n        const onInput = (e) => {\n          pause();\n          setStep(parseInt(e.target.value) - 1);\n        };\n\n        return h`\n          <div className=${props.className}>\n            <${PlayButton} onClick=${onClick}><svg xmlns=&quot;http://www.w3.org/2000/svg&quot; width=&quot;24px&quot; height=&quot;24px&quot; viewBox=&quot;0 0 24 24&quot; fill=&quot;#FFFFFF&quot;>${\n          playing\n            ? h`<path d=&quot;M6 19h4V5H6v14zm8-14v14h4V5h-4z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n            : h`<path d=&quot;M8 5v14l11-7z&quot;/><path d=&quot;M0 0h24v24H0z&quot; fill=&quot;none&quot;/>`\n        }</svg><//>\n            <${StepInput} min=&quot;1&quot; max=${\n          environment.steps.length\n        } value=&quot;${value}&quot; onInput=${onInput} />\n            <${StepCount}>${value} / ${environment.steps.length}<//>\n          </div>\n        `;\n      })`\n        align-items: center;\n        border-top: 4px solid #212121;\n        display: flex;\n        flex: 0 0 44px;\n        width: 100%;\n      `;\n\n      const Info = styled((props) => {\n        const {\n          environment,\n          playing,\n          step,\n          speed,\n          animate,\n          header,\n          controls,\n          settings,\n        } = useContext(Context);\n\n        return h`\n          <div className=${props.className}>\n            info:\n            step(${step}),\n            playing(${playing ? &quot;T&quot; : &quot;F&quot;}),\n            speed(${speed}),\n            animate(${animate ? &quot;T&quot; : &quot;F&quot;})\n          </div>`;\n      })`\n        color: #888;\n        font-family: monospace;\n        font-size: 12px;\n      `;\n\n      const Settings = styled((props) => {\n        const { environment, pause, play, playing, setStep, step } = useContext(\n          Context\n        );\n\n        return h`\n          <div className=${props.className}>\n            <${Info} />\n          </div>\n        `;\n      })`\n        background: #fff;\n        border-top: 4px solid #212121;\n        box-sizing: border-box;\n        padding: 20px;\n        width: 100%;\n\n        h1 {\n          font-size: 20px;\n        }\n      `;\n\n      const Player = styled((props) => {\n        const context = useContext(Context);\n        const { agents, controls, header, legend, loading, settings, width } = context;\n        return h`\n          <div className=${props.className}>\n            ${loading && h`<${Loading} />`}\n            ${!loading && header && h`<${Header} />`}\n            ${!loading && h`<${Viewer} />`}\n            ${!loading && legend && h`<${Legend} width=${width}/>`}\n            ${!loading && controls && h`<${Controls} />`}\n            ${!loading && settings && h`<${Settings} />`}\n          </div>`;\n      })`\n        align-items: center;\n        background: #212121;\n        border: 4px solid #212121;\n        box-sizing: border-box;\n        display: flex;\n        flex-direction: column;\n        height: 100%;\n        justify-content: center;\n        position: relative;\n        width: 100%;\n      `;\n\n      const App = () => {\n        const renderCountRef = useRef(0);\n        const [_, setRenderCount] = useState(0);\n\n        // These are bindings to the 0-9 keys and are milliseconds of timeout per step\n        const speeds = [\n          0,\n          3000,\n          1000,\n          500,\n          333, // Default\n          200,\n          100,\n          50,\n          25,\n          10,\n        ];\n\n        const contextRef = useRef({\n          animate: false,\n          agents: [],\n          controls: false,\n          debug: false,\n          environment: { steps: [], info: {} },\n          header: window.innerHeight >= 600,\n          height: window.innerHeight,\n          interactive: false,\n          legend: true,\n          loading: false,\n          playing: false,\n          processing: false,\n          renderer: () => &quot;DNE&quot;,\n          settings: false,\n          speed: speeds[4],\n          step: 0,\n          width: window.innerWidth,\n        });\n\n        // Context helpers.\n        const rerender = (contextRef.current.rerender = () =>\n          setRenderCount((renderCountRef.current += 1)));\n        const setStep = (contextRef.current.setStep = (newStep) => {\n          contextRef.current.step = newStep;\n          rerender();\n        });\n        const setPlaying = (contextRef.current.setPlaying = (playing) => {\n          contextRef.current.playing = playing;\n          rerender();\n        });\n        const pause = (contextRef.current.pause = () => setPlaying(false));\n\n        const playNext = () => {\n          const context = contextRef.current;\n\n          if (\n            context.playing &&\n            context.step < context.environment.steps.length - 1\n          ) {\n            setStep(context.step + 1);\n            play(true);\n          } else {\n            pause();\n          }\n        };\n\n        const play = (contextRef.current.play = (continuing) => {\n          const context = contextRef.current;\n          if (context.playing && !continuing) return;\n          if (!context.playing) setPlaying(true);\n          if (\n            !continuing &&\n            context.step === context.environment.steps.length - 1\n          ) {\n            setStep(0);\n          }\n          setTimeout(playNext, context.speed);\n        });\n\n        const updateContext = (o) => {\n          const context = contextRef.current;\n          Object.assign(context, o, {\n            environment: { ...context.environment, ...(o.environment || {}) },\n          });\n          rerender();\n        };\n\n        // First time setup.\n        useEffect(() => {\n          // Timeout is used to ensure useEffect renders once.\n          setTimeout(() => {\n            // Initialize context with window.kaggle.\n            updateContext(window.kaggle || {});\n\n            if (window.kaggle.playing) {\n                play(true);\n            }\n\n            // Listen for messages received to update the context.\n            window.addEventListener(\n              &quot;message&quot;,\n              (event) => {\n                // Ensure the environment names match before updating.\n                try {\n                  if (\n                    event.data.environment.name ==\n                    contextRef.current.environment.name\n                  ) {\n                    updateContext(event.data);\n                  }\n                } catch {}\n              },\n              false\n            );\n            // Listen for keyboard commands.\n            window.addEventListener(\n              &quot;keydown&quot;,\n              (event) => {\n                const {\n                  interactive,\n                  isInteractive,\n                  playing,\n                  step,\n                  environment,\n                } = contextRef.current;\n                const key = event.keyCode;\n                const zero_key = 48\n                const nine_key = 57\n                if (\n                  interactive ||\n                  isInteractive() ||\n                  (key !== 32 && key !== 37 && key !== 39 && !(key >= zero_key && key <= nine_key))\n                )\n                  return;\n\n                if (key === 32) {\n                  playing ? pause() : play();\n                } else if (key === 39) {\n                  contextRef.current.playing = false;\n                  if (step < environment.steps.length - 1) setStep(step + 1);\n                  rerender();\n                } else if (key === 37) {\n                  contextRef.current.playing = false;\n                  if (step > 0) setStep(step - 1);\n                  rerender();\n                } else if (key >= zero_key && key <= nine_key) {\n                  contextRef.current.speed = speeds[key - zero_key];\n                }\n                event.preventDefault();\n                return false;\n              },\n              false\n            );\n          }, 1);\n        }, []);\n\n        if (contextRef.current.debug) {\n          console.log(&quot;context&quot;, contextRef.current);\n        }\n\n        // Ability to update context.\n        contextRef.current.update = updateContext;\n\n        // Ability to communicate with ipython.\n        const execute = (contextRef.current.execute = (source) =>\n          new Promise((resolve, reject) => {\n            try {\n              window.parent.IPython.notebook.kernel.execute(source, {\n                iopub: {\n                  output: (resp) => {\n                    const type = resp.msg_type;\n                    if (type === &quot;stream&quot;) return resolve(resp.content.text);\n                    if (type === &quot;error&quot;) return reject(new Error(resp.evalue));\n                    return reject(new Error(&quot;Unknown message type: &quot; + type));\n                  },\n                },\n              });\n            } catch (e) {\n              reject(new Error(&quot;IPython Unavailable: &quot; + e));\n            }\n          }));\n\n        // Ability to return an action from an interactive session.\n        contextRef.current.act = (action) => {\n          const id = contextRef.current.environment.id;\n          updateContext({ processing: true });\n          execute(`\n            import json\n            from kaggle_environments import interactives\n            if &quot;${id}&quot; in interactives:\n                action = json.loads('${JSON.stringify(action)}')\n                env, trainer = interactives[&quot;${id}&quot;]\n                trainer.step(action)\n                print(json.dumps(env.steps))`)\n            .then((resp) => {\n              try {\n                updateContext({\n                  processing: false,\n                  environment: { steps: JSON.parse(resp) },\n                });\n                play();\n              } catch (e) {\n                updateContext({ processing: resp.split(&quot;\\n&quot;)[0] });\n                console.error(resp, e);\n              }\n            })\n            .catch((e) => console.error(e));\n        };\n\n        // Check if currently interactive.\n        contextRef.current.isInteractive = () => {\n          const context = contextRef.current;\n          const steps = context.environment.steps;\n          return (\n            context.interactive &&\n            !context.processing &&\n            context.step === steps.length - 1 &&\n            steps[context.step].some((s) => s.status === &quot;ACTIVE&quot;)\n          );\n        };\n\n        return h`\n          <${Context.Provider} value=${contextRef.current}>\n            <${Player} />\n          <//>`;\n      };\n\n      preact.render(h`<${App} />`, document.body);\n    </script>\n  </body>\n</html>\n\" width=\"500\" height=\"450\" frameborder=\"0\"></iframe> "
     },
     "metadata": {}
    }
   ],
   "source": [
    "env.reset()\n",
    "# Play as the first agent against default \"random\" agent.\n",
    "env.run([agent, \"random\"])\n",
    "env.render(mode=\"ipython\", width=500, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(env.configuration.columns*env.configuration.rows, 300, env.configuration.columns)\n",
    "model.load_state_dict(torch.load(\"model_state\"))\n",
    "def agent1(obs, config):\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor(obs['board'], dtype=torch.float)\n",
    "        col = model(state).argmax().item()\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Agent 1 Win Percentage: 0.0\nAgent 2 Win Percentage: 0.39\nNumber of Invalid Plays by Agent 1: 61\nNumber of Invalid Plays by Agent 2: 0\n"
     ]
    }
   ],
   "source": [
    "get_win_percentages(agent1, 'negamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0904,  0.0919,  0.1277,  ..., -0.0106,  0.1755, -0.1241],\n        [-0.0072,  0.1276,  0.0015,  ...,  0.0168,  0.0184,  0.0091],\n        [ 0.1542, -0.0082,  0.0211,  ..., -0.0545, -0.0861, -0.1002],\n        ...,\n        [-0.1185,  0.0440, -0.0660,  ..., -0.0116, -0.0241, -0.1110],\n        [-0.0826, -0.1225, -0.0858,  ...,  0.0593,  0.0191, -0.0637],\n        [ 0.1158, -0.1356, -0.1062,  ..., -0.0026, -0.1227, -0.1448]])\ntensor([ 0.0595,  0.0143,  0.0345,  0.0101, -0.0403,  0.0387,  0.0478, -0.0193,\n        -0.1549,  0.0101, -0.1366, -0.0428,  0.0471, -0.0494,  0.0072, -0.0443,\n         0.0056, -0.1984, -0.0797, -0.0769, -0.2006, -0.1961, -0.0321, -0.1634,\n         0.0785, -0.1429, -0.0294, -0.0915,  0.0035,  0.0097,  0.0786,  0.0014,\n        -0.1533, -0.0602,  0.0042, -0.2130,  0.1134, -0.1177, -0.0034, -0.0033,\n        -0.0710, -0.1049, -0.1177,  0.0416, -0.2251, -0.0176, -0.0630,  0.0462,\n        -0.0784,  0.0256, -0.1192, -0.1507, -0.0229,  0.0679,  0.0833, -0.0909,\n        -0.0644, -0.0469, -0.0465, -0.1356,  0.0338, -0.1707,  0.0484, -0.0153,\n         0.1557, -0.0620,  0.0887,  0.0167, -0.0721,  0.0592, -0.0233, -0.1029,\n        -0.0575,  0.0982,  0.0494,  0.0343, -0.2054,  0.0444, -0.0316, -0.1889,\n         0.0241,  0.0459, -0.0754, -0.0504, -0.0388,  0.0905, -0.0637, -0.2213,\n         0.1548, -0.0684,  0.1121, -0.0072,  0.0490, -0.0349,  0.0215, -0.0751,\n        -0.0066, -0.0267, -0.0174,  0.0942,  0.0853,  0.0812, -0.0712, -0.1048,\n        -0.1476, -0.1089, -0.0057, -0.1581,  0.0653,  0.0169, -0.1009, -0.1089,\n        -0.0388, -0.0643, -0.0417, -0.0711, -0.1202, -0.1124,  0.0039, -0.0102,\n        -0.0189, -0.0422, -0.1282, -0.0163, -0.1522, -0.0817, -0.1346,  0.0930,\n         0.0453,  0.0464, -0.0863, -0.2308, -0.0710, -0.0305,  0.0360, -0.1040,\n        -0.1484, -0.0466, -0.0636, -0.1294, -0.1151,  0.0806, -0.1208, -0.0617,\n        -0.0678, -0.0652, -0.0378, -0.3260, -0.1196,  0.0005, -0.0669,  0.0313,\n        -0.1511, -0.1178, -0.0536, -0.0778, -0.0739, -0.0185,  0.0139, -0.1606,\n        -0.0750, -0.0246,  0.0708,  0.0551, -0.0061,  0.0401, -0.0160, -0.0749,\n         0.0486, -0.0860, -0.2071,  0.1064, -0.1321, -0.1104, -0.0295,  0.1163,\n        -0.0181, -0.0425, -0.2015, -0.0607,  0.0643, -0.1468, -0.1150, -0.1364,\n        -0.1505, -0.1659,  0.0489, -0.0824, -0.0417,  0.1037, -0.0850, -0.0881,\n        -0.0677, -0.1900, -0.0279, -0.0230,  0.0630,  0.0785, -0.1994, -0.2040,\n        -0.0084, -0.0036, -0.0493, -0.0694,  0.0159, -0.1258,  0.0586, -0.1491,\n        -0.1139, -0.0859, -0.2356, -0.0940, -0.0427,  0.0125,  0.0191, -0.1109,\n        -0.1240, -0.0133,  0.0237, -0.0664, -0.0622, -0.0923, -0.2322, -0.0789,\n         0.0210,  0.0329,  0.0973, -0.0743, -0.1097, -0.0030,  0.0410, -0.0212,\n        -0.0130, -0.0354, -0.0746,  0.0318,  0.0215,  0.0276, -0.1375,  0.1272,\n         0.0184, -0.1648,  0.0367, -0.1653,  0.0293, -0.0806, -0.1494, -0.0976,\n        -0.0394, -0.0134,  0.0906,  0.0565, -0.0227, -0.1942,  0.1346,  0.0881,\n        -0.0034, -0.0514,  0.0445, -0.0097, -0.2677, -0.0122, -0.0566, -0.1665,\n         0.0734, -0.2207, -0.2067,  0.0177, -0.1224, -0.0396, -0.0978, -0.1131,\n        -0.1575, -0.2212,  0.0313, -0.0457,  0.0197, -0.0466, -0.0095, -0.0176,\n         0.0457,  0.0096, -0.0264,  0.0386, -0.1203,  0.0118, -0.0537,  0.0310,\n         0.0232, -0.0275, -0.0055,  0.0758, -0.0134,  0.0020, -0.0034,  0.0537,\n         0.0336,  0.0161, -0.0265, -0.0452])\ntensor([[ 0.0805,  0.0611,  0.1417,  ...,  0.0194, -0.0017,  0.0104],\n        [ 0.0031, -0.0092, -0.0648,  ..., -0.0950, -0.0878, -0.0793],\n        [-0.0611, -0.1038,  0.0796,  ...,  0.0110,  0.0201,  0.0509],\n        ...,\n        [-0.0635, -0.0989,  0.0065,  ..., -0.0267, -0.0864, -0.0393],\n        [-0.0741, -0.0809,  0.1094,  ...,  0.0717,  0.0327,  0.0527],\n        [ 0.0153,  0.0362, -0.0577,  ..., -0.0910, -0.0494, -0.0613]])\ntensor([ 0.1086, -0.0302,  0.0607, -0.0302, -0.0027, -0.1111, -0.0415, -0.0445,\n         0.0037, -0.0676, -0.0900, -0.0696,  0.0354, -0.0093, -0.0627, -0.0826,\n         0.1663, -0.0035, -0.0239, -0.0156,  0.0993, -0.0215, -0.0517, -0.0335,\n        -0.0342, -0.0048, -0.0199, -0.0088, -0.0800, -0.0470, -0.0830,  0.0062,\n        -0.0525,  0.1123,  0.0425,  0.1564, -0.0391, -0.0524, -0.0070, -0.0560,\n         0.0143, -0.0738, -0.0247,  0.0244, -0.0032, -0.0328, -0.0333,  0.1649,\n        -0.0995, -0.0535, -0.0986, -0.1375, -0.0774,  0.0966,  0.0817, -0.0125,\n         0.0101, -0.0926, -0.0254, -0.0843, -0.0401, -0.0547, -0.0413,  0.0386,\n         0.1991, -0.0253, -0.0952,  0.0292, -0.0466,  0.0634, -0.0429, -0.0227,\n        -0.0970, -0.0575, -0.1057, -0.0412, -0.0507, -0.0518, -0.0314, -0.0198,\n        -0.0622,  0.1671, -0.0545, -0.0989, -0.0083, -0.0186, -0.0100, -0.0759,\n        -0.0678,  0.0067, -0.0094, -0.0294, -0.0921,  0.0191, -0.0184,  0.0185,\n         0.0548, -0.0490, -0.0820, -0.0375, -0.0527, -0.0134,  0.0497, -0.0170,\n        -0.0095, -0.0662, -0.0541,  0.0966,  0.0587,  0.0382,  0.0389,  0.0657,\n        -0.0106,  0.0097, -0.0573,  0.0236,  0.0442, -0.0878, -0.0277, -0.1209,\n        -0.0247, -0.0226, -0.0770, -0.0178, -0.0787, -0.0376,  0.0039, -0.0678,\n        -0.0764, -0.0297, -0.0414, -0.0688, -0.0466, -0.0518,  0.0730,  0.0110,\n        -0.0457, -0.0147, -0.0842, -0.0288, -0.0723,  0.0379,  0.0508, -0.0847,\n        -0.1167, -0.0147,  0.0557, -0.1094, -0.0769, -0.0114, -0.0296, -0.0261,\n        -0.0302, -0.0405, -0.0152, -0.0377, -0.0116, -0.0154, -0.0201, -0.1008,\n        -0.0080, -0.0094, -0.0676,  0.0235, -0.0062,  0.2289, -0.0718, -0.0915,\n        -0.0416, -0.0219, -0.0024, -0.0324, -0.0332, -0.1055,  0.0343, -0.0461,\n         0.0932,  0.0775,  0.1140, -0.1039, -0.0507, -0.0124,  0.0141, -0.0718,\n        -0.0411, -0.0049, -0.1035, -0.0477,  0.1564, -0.1133,  0.0412, -0.1025,\n         0.0819, -0.1035, -0.0826, -0.0935,  0.0320, -0.0353,  0.0670, -0.0427,\n         0.0678,  0.0079, -0.0403, -0.0385, -0.0665, -0.0466,  0.0962, -0.0796,\n        -0.0671, -0.0822, -0.0754, -0.1080, -0.0148, -0.0478, -0.0695,  0.0274,\n        -0.0887, -0.0169,  0.0279,  0.0038, -0.0315,  0.1084, -0.0175, -0.0888,\n         0.0246, -0.0235, -0.0498, -0.0881, -0.0472, -0.0956, -0.0732,  0.0886,\n        -0.0162, -0.0043, -0.1087, -0.0380, -0.0260, -0.0301,  0.0466,  0.0268,\n        -0.0610, -0.0301, -0.0166, -0.0721, -0.0229,  0.0355, -0.0398,  0.1629,\n        -0.0545, -0.0445, -0.0701,  0.0283, -0.0300,  0.0031, -0.1207, -0.0621,\n        -0.0678, -0.0783, -0.0314, -0.0987, -0.0592, -0.0880, -0.0357, -0.0445,\n        -0.0151,  0.0448,  0.0072,  0.1886,  0.0083, -0.0551,  0.1570,  0.0365,\n        -0.0120, -0.0994, -0.0988, -0.0126, -0.0851, -0.0792,  0.0011, -0.0103,\n        -0.0754,  0.0449, -0.0199, -0.1104, -0.0042, -0.0559, -0.0622,  0.0327,\n        -0.0453, -0.0077, -0.0279, -0.0499, -0.0829, -0.0172, -0.0559, -0.0293,\n        -0.0644, -0.0585,  0.0399, -0.0391])\ntensor([[-0.0895,  0.0719, -0.0651,  ...,  0.0011, -0.1003,  0.0193],\n        [-0.0767,  0.0786, -0.0175,  ..., -0.0449, -0.0237,  0.1168],\n        [-0.1112, -0.0274, -0.0750,  ...,  0.0209,  0.0204, -0.0189],\n        ...,\n        [-0.0260,  0.0014, -0.0623,  ..., -0.0715, -0.0856, -0.0425],\n        [-0.0835,  0.1086, -0.0829,  ..., -0.0857, -0.0931,  0.0788],\n        [-0.1242, -0.0312, -0.0542,  ..., -0.0019, -0.0065,  0.0514]])\ntensor([ 1.5329e-02,  2.5522e-02, -1.0745e-02, -8.1360e-06, -1.2395e-01,\n        -7.1534e-03, -1.2477e-01])\n"
     ]
    }
   ],
   "source": [
    "model = Net(env.configuration.columns*env.configuration.rows, 300, env.configuration.columns)\n",
    "model.load_state_dict(torch.load(\"model_state\"))\n",
    "for param in model.parameters():\n",
    "  print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}